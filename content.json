{"meta":{"title":"Keyang's Blog","subtitle":"A home of Javascript","description":null,"author":"Keyang Xiang","url":"http://keyangxiang.com","root":"/"},"pages":[{"title":"","date":"2018-12-19T17:52:51.549Z","updated":"2018-03-06T22:00:53.000Z","comments":true,"path":"google74ef30bb51b6688b.html","permalink":"http://keyangxiang.com/google74ef30bb51b6688b.html","excerpt":"","text":"google-site-verification: google74ef30bb51b6688b.html"},{"title":"","date":"2018-12-19T17:52:51.550Z","updated":"2017-12-22T16:12:26.000Z","comments":true,"path":"index1.html","permalink":"http://keyangxiang.com/index1.html","excerpt":"","text":"Keyang's Homepage window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-29275086-1'); Goto Blog >>> Hi! This is Keyang from Redhat. I live in beautiful Ireland. I love coding, cooking, and fishing. You can find me in: You may be interested in: CSVTOJSON Fastest Node.js CSV parser. PSDETCH A design tool for developers."},{"title":"About Me","date":"2015-11-11T18:34:11.000Z","updated":"2016-01-10T06:34:07.000Z","comments":true,"path":"about/index.html","permalink":"http://keyangxiang.com/about/index.html","excerpt":"","text":"this is about me"},{"title":"","date":"2018-12-19T17:52:51.545Z","updated":"2017-07-08T21:40:04.000Z","comments":true,"path":"base64/base64.js","permalink":"http://keyangxiang.com/base64/base64.js","excerpt":"","text":"(function () { var url = location.href; var search = url.split(\"?\")[1]; if (search) { var parts = search.split(\"&\"); var data = null; var fileName = null; parts.forEach(function (p) { if (p.indexOf(\"base64\") > -1) { data =decodeURIComponent(p.replace(\"base64=\", \"\")); } else if (p.indexOf(\"fileName\") > -1) { fileName = decodeURIComponent( p.replace(\"fileName=\", \"\")); } }); if (data && fileName) { var a = document.createElement(\"a\"); a.download = fileName; a.href = data; a.click(); } } })();"},{"title":"Base64 encoder | decoder.","date":"2018-12-19T17:52:51.546Z","updated":"2017-07-08T21:19:32.000Z","comments":false,"path":"base64/index.html","permalink":"http://keyangxiang.com/base64/index.html","excerpt":"","text":"## Usage As API: 1http://keyangxiang.com/base64/?base64=&lt;data&gt;&amp;fileName=&lt;string&gt;"},{"title":"","date":"2015-11-11T18:34:11.000Z","updated":"2017-08-16T21:14:22.000Z","comments":true,"path":"blog/index.html","permalink":"http://keyangxiang.com/blog/index.html","excerpt":"","text":""},{"title":"","date":"2018-12-19T17:52:51.548Z","updated":"2016-04-30T10:55:46.000Z","comments":true,"path":"csvtojson/c2j.css","permalink":"http://keyangxiang.com/csvtojson/c2j.css","excerpt":"","text":".section{ margin-bottom:8px; } .txtBox{ width:100%; min-height:500px; border:3px solid #ccc; box-sizing: border-box; padding:5px; background:#efefef; resize:vertical; outline:none; } .txtBox:focus{ border:3px solid #999; } .btn{ text-align: center; border:2px solid #ccc; box-sizing: border-box; padding: 10px; cursor: pointer; } .btn:hover{ background: #efefef; } .btn:active{ background: #ccc; } .btn.on{ background: #ccc; } .btn.btn-inline{ display: inline-block; } #result{ display: none; } #jsonRes{ cursor: pointer; } #toggleParams{ max-width:150px; } input.sm{ width:12px; } .clearfix:after { content: \" \"; /* Older browser do not support empty content */ visibility: hidden; display: block; height: 0; clear: both; } .col-3-item>span{ width:31%; margin-right:1%; float:left; display: block; } .col-4-item>span{ width:24%; margin-right:1%; float:left; display: block; } .col-2-item>span{ width:48%; margin-right:1%; display: inline-block; } input.dyna{ width:65%; } #paramBox{ padding:5px; margin-top:5px; margin-bottom:5px; border:2px solid #eee; border-radius: 3px; font-size:0.8em; display: none; } .right{ float:right; } .compact>div{ line-height:14px; }"},{"title":"","date":"2018-12-19T17:52:51.548Z","updated":"2018-06-23T19:18:44.000Z","comments":true,"path":"csvtojson/index.html","permalink":"http://keyangxiang.com/csvtojson/index.html","excerpt":"","text":"CSV to JSON has been moved to here. Click the link if browser is not redirecting automatically."},{"title":"Projects","date":"2018-12-19T17:52:51.551Z","updated":"2016-01-10T14:08:40.000Z","comments":true,"path":"projects/index.html","permalink":"http://keyangxiang.com/projects/index.html","excerpt":"","text":"Node.JS csvtojsonA comprehensive csv to json converter module"},{"title":"","date":"2018-12-19T17:52:51.552Z","updated":"2017-09-05T23:17:06.000Z","comments":true,"path":"simplepsd/index.html","permalink":"http://keyangxiang.com/simplepsd/index.html","excerpt":"","text":"Simplepsd has been moved to here. Click the link if browser is not redirecting automatically."}],"posts":[{"title":"hello","slug":"hello","date":"2019-09-06T15:50:55.000Z","updated":"2019-09-06T15:51:43.515Z","comments":true,"path":"2019/09/06/hello/","link":"","permalink":"http://keyangxiang.com/2019/09/06/hello/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Run Nginx as reverse proxy on Openshift","slug":"Openshift/how-to-run-nginx-as-reverse-proxy","date":"2018-06-01T16:32:24.000Z","updated":"2018-06-14T10:12:55.000Z","comments":true,"path":"2018/06/01/Openshift/how-to-run-nginx-as-reverse-proxy/","link":"","permalink":"http://keyangxiang.com/2018/06/01/Openshift/how-to-run-nginx-as-reverse-proxy/","excerpt":"In this post, I will introduce a way to deploy a Nginx Reverse Proxy to Openshift base on RedHat certified Nginx Builder Image.","text":"In this post, I will introduce a way to deploy a Nginx Reverse Proxy to Openshift base on RedHat certified Nginx Builder Image. In my previous post: How to deploy website to openshift with nginx, I simply introduced how to use the Nginx Builder Image to deploy a website on Openshift. Reverse Proxy configuration, however, is not part of web content. Thus it is not able to directly to use the Builder Image to setup the config and we will need create a real Nginx Image which can be futher configured with reverse proxy table. Step 1 – Create Nginx base imageWe are creating the Nginx Base Image based on RedHat certified Nginx Builder Image (rhscl/nginx-112-rhel7). First, let’s create an app that has an empty index.html page from local directory (e.g. $HOME/webfolder): 1oc new-app registry.access.redhat.com/rhscl/nginx-112-rhel7~$HOME/webfolder --name=nginxbase This will create corresponding resources like buildconfig, deploymentconfig, imagestream, service etc for nginxbase in Openshift. Once resources created successfully, let’s build the image 1oc start-build nginxbase --from-dir=$HOME/webfolder This will create the Nginx Base image and push to registry in Openshift. Once the nginxbase image being created, we could remove all other resources: 123oc delete bc/nginxbaseoc delete dc/nginxbaseoc delete svc/nginxbase Step 2 – Add reverse proxy configurationWe will need create a custom image for reverse proxy. First, create an empty folder and add following files: Dockerfile nginx-proxy.conf: the proxy definition file In Dockerfile, add following content: 12FROM nginxbase:latestADD nginx-proxy.conf /opt/app-root/etc/nginx.default.d/nginx-proxy.conf When nginx server starts, it will automatically load configuration files *.conf in /opt/app-root/etc/nginx.default.d folder into its default server definition closure. So we add our nginx-proxy configuration file into that folder. In nginx-proxy.conf file, we could add reverse proxy configuration. For example: 12345678910111213141516171819location /userProfile &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto https; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header X-Forwarded-Host $remote_addr; proxy_pass http://userProfile:8080;&#125;location /uploadAsset &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto https; proxy_set_header X-Forwarded-For $remote_addr; proxy_set_header X-Forwarded-Host $remote_addr; proxy_buffering off; client_max_body_size 50m; proxy_pass http://uploadAsset:8080;&#125; Step 3 – Create Reverse ProxyNext, create reverse proxy app in Openshift: 1oc new-app --strategy=docker nginxbase~&lt;path to dockerfile&gt; --name=myReverseProxy Just be aware we have to use docker strategy as app’s build strategy so that Openshift knows that we will upload a Docker project. Start Build: 1oc start-build myReverseProxy --from-dir=&lt;path to dockerfile&gt; Once the build finished, Openshift should automatically deploy a new pod up and running. We could expose the reverse proxy by running 1oc expose svc/myReverseProxy and access the nginx reverse proxy through the routes created.","categories":[{"name":"Openshift","slug":"Openshift","permalink":"http://keyangxiang.com/categories/Openshift/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://keyangxiang.com/tags/nginx/"},{"name":"openshift","slug":"openshift","permalink":"http://keyangxiang.com/tags/openshift/"}]},{"title":"How to Run Minishift On MacOSX","slug":"Openshift/how-to-run-minishift-on-macos","date":"2018-05-18T17:40:23.000Z","updated":"2018-05-18T09:50:41.000Z","comments":true,"path":"2018/05/18/Openshift/how-to-run-minishift-on-macos/","link":"","permalink":"http://keyangxiang.com/2018/05/18/Openshift/how-to-run-minishift-on-macos/","excerpt":"Minishift allows running a mini-version of Openshift cluster locally for convenience of development and debug. This blog is going through how to run minishift on MacOS.","text":"Minishift allows running a mini-version of Openshift cluster locally for convenience of development and debug. This blog is going through how to run minishift on MacOS. Step1 – Download latest MinishiftGoto Mnishift Github Release Page, it is able to see the binary assets of Minishift for different operation systems. By writing this article, the latest versino of Minishift for MacOS is minishift-1.17.0-darwin-amd64.tgz. Once downloaded, expand the tar file and copy the minishift file to /usr/local/bin folder 123456# untar the downloaded filetar -xvf ~/Downloads/&lt;downloaded file&gt;sudo cp ~/Downloads/&lt;expanded folder&gt;/minishift /usr/local/binsudo chmod +x /usr/local/bin/minishift Step2 – Install dependencies / Virtualization EnvironmentBefore Minishift can run, we need setup the virualization environment which supports Openshift running under MacOS environment. When doing this step, I assum you have brew installed /configured correctly in your computer. You can simply copy and paste code below and run in a terminal. 123456# Update brew firstbrew update# install docker-machine-driver-xhyvebrew install docker-machine-driver-xhyve# Set the owner User ID (SUID) for the binary sudo chmod u+s $(brew --prefix)/opt/docker-machine-driver-xhyve/bin/docker-machine-driver-xhyve Step 3 – Run minishiftOnce setup virtualization environment successfully, let’s start minishift: 1minishift start For first time running, it will download all related dependencies including images / cli binary . After starting successfully, it is able to see the allocated IP address to the master node of the openshift cluster. In my case it is 192.168.64.2. Then you should be able to open https://192.168.64.2:8443 in your browser and login with username and password both as admin. To shutdown your minishift cluster simply run: 1minishift stop","categories":[{"name":"Openshift","slug":"Openshift","permalink":"http://keyangxiang.com/categories/Openshift/"}],"tags":[{"name":"openshift","slug":"openshift","permalink":"http://keyangxiang.com/tags/openshift/"},{"name":"minishift","slug":"minishift","permalink":"http://keyangxiang.com/tags/minishift/"}]},{"title":"How to install Node.JS locally","slug":"node.js/how-to-install","date":"2018-04-01T15:30:12.000Z","updated":"2018-05-18T09:48:58.000Z","comments":true,"path":"2018/04/01/node.js/how-to-install/","link":"","permalink":"http://keyangxiang.com/2018/04/01/node.js/how-to-install/","excerpt":"Installing Node.JS locally will take no more than 5 minutes. This post will go through the steps very quickly.","text":"Installing Node.JS locally will take no more than 5 minutes. This post will go through the steps very quickly. Download InstallerFirst, download Node.JS installer according to target operation system from here The installer downloaded should be executable on target operation system (e.g. .msi on Window and .pkg on MacOSX) Run InstallerFollow the wizard and install Node.JS to target machine. Restart and TestOnce installation finished, open a bash or cmd. Installation should have both node and npm commands exposed. 1234$ node --versionv6.9.5$ npm --version3.10.10 It is essential to have both commands running correctly.","categories":[{"name":"Node.JS","slug":"Node-JS","permalink":"http://keyangxiang.com/categories/Node-JS/"}],"tags":[{"name":"nodejs","slug":"nodejs","permalink":"http://keyangxiang.com/tags/nodejs/"}]},{"title":"What is Node.JS? Why should I care?","slug":"node.js/about-nodejs","date":"2018-03-31T11:45:31.000Z","updated":"2018-04-02T21:07:28.000Z","comments":true,"path":"2018/03/31/node.js/about-nodejs/","link":"","permalink":"http://keyangxiang.com/2018/03/31/node.js/about-nodejs/","excerpt":"","text":"Node.JS has been attracting attentions for years. What is Node.JS? What makes it unique? Why should developers care about it?","categories":[{"name":"Node.JS","slug":"Node-JS","permalink":"http://keyangxiang.com/categories/Node-JS/"}],"tags":[{"name":"nodejs","slug":"nodejs","permalink":"http://keyangxiang.com/tags/nodejs/"}]},{"title":"How to deploy website to openshift with nginx?","slug":"Openshift/How-to-run-nginx-on-openshift-and-deploy-website","date":"2017-10-24T21:04:14.000Z","updated":"2018-05-18T09:58:33.000Z","comments":true,"path":"2017/10/24/Openshift/How-to-run-nginx-on-openshift-and-deploy-website/","link":"","permalink":"http://keyangxiang.com/2017/10/24/Openshift/How-to-run-nginx-on-openshift-and-deploy-website/","excerpt":"Although Openshift is able to use docker images, it has much more restrictions like no root user. Thus not all docker images can work straight on Openshift. Unfortunately, the official nginx docker image does not work on openshift. In this post, I will simply go through how to run this Official RedHat nginx image on Openshift and deploy a website onto it.","text":"Although Openshift is able to use docker images, it has much more restrictions like no root user. Thus not all docker images can work straight on Openshift. Unfortunately, the official nginx docker image does not work on openshift. In this post, I will simply go through how to run this Official RedHat nginx image on Openshift and deploy a website onto it. So, have your openshift cli tool (oc) ready, let’s get started. Step 1 - Create App / Deploy website source codeWith oc tool, create a new app. 12#oc new-app [BuilderImage]~[Source Code Repo]oc new-app registry.access.redhat.com/rhscl/nginx-112-rhel7~https://github.com/Keyang/keyang.github.io.git --name=myapp The openshift will pull the image from the registry and register it locally as builder image which will allow building images along with source code of website. It creates build config. Then it will pull source code and assemble it with build image to produce another image stream. This command will also create deployment config and service. Build Local SourceIf you have no accessible git repo, it is able to build againt local source. Slightly different, create a new app on current folder 12#oc new-app [BuilderImage]~[Source Code Repo]oc new-app nginx-112-rhel7~./ --name=myapp This will not actually upload the source code from current folder to Openshift but just create a build config. Thus we need to start the build with extra parameters: 1oc start-build myapp --from-dir=./ with --from-dir param, oc will upload content of current directory and builder image will assemble the code. Step 2 - Expose Nginx ServerOnce app is created and built, we could expose it through router. 1oc expose svc/myapp Once it is exposed, your nginx server and your website should be accessible with the route associated.","categories":[{"name":"Openshift","slug":"Openshift","permalink":"http://keyangxiang.com/categories/Openshift/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://keyangxiang.com/tags/nginx/"},{"name":"openshift","slug":"openshift","permalink":"http://keyangxiang.com/tags/openshift/"}]},{"title":"How to download binary content as Blob in JS with Ajax(XHR)","slug":"HTML5-XHR-download-binary-content-as-Blob","date":"2017-09-01T22:32:13.000Z","updated":"2017-12-22T23:35:00.000Z","comments":true,"path":"2017/09/01/HTML5-XHR-download-binary-content-as-Blob/","link":"","permalink":"http://keyangxiang.com/2017/09/01/HTML5-XHR-download-binary-content-as-Blob/","excerpt":"Using XMLHTTPRequest (ajax) transporting data between client and server has been popular for a while. Sometimes, we want our browser to retrieve binary data from server (as ArrayBuffer or Blob) such as pdf, image, and psd files. This post will go through how to achieve it with XMLHTTPRequest and jQuery.","text":"Using XMLHTTPRequest (ajax) transporting data between client and server has been popular for a while. Sometimes, we want our browser to retrieve binary data from server (as ArrayBuffer or Blob) such as pdf, image, and psd files. This post will go through how to achieve it with XMLHTTPRequest and jQuery. Download Binary using XMLHTTPRequestFor XMLHTTPRequest, just simply setup the responseType of XHR instance to either arraybuffer or blob. Example: 1234567891011var xhr=new XMLHTTPRequest();xhr.open(\"GET\", url, true);//Now set response typexhr.responseType = 'arraybuffer';xhr.addEventListener('load',function()&#123; if (xhr.status === 200)&#123; console.log(xhr.response) // ArrayBuffer console.log(new Blob([xhr.response])) // Blob &#125;&#125;)xhr.send(); Download with jQuery Ajax$.ajax does not support either arraybuffer or blob as its dataType. Thus we need write a beforeSend handler: 12345678910111213141516171819//setup ajax$.ajaxSetup(&#123; beforeSend:function(jqXHR,settings)&#123; if (settings.dataType === 'binary')&#123; settings.xhr().responseType='arraybuffer'; settings.processData=false; &#125; &#125;&#125;)//use ajax now$.ajax(&#123; url:url, dataType:\"binary\", success:function(data)&#123; console.log(data); //ArrayBuffer console.log(new Blob([data])) // Blob &#125;&#125;) About ResponseTypeFor more information about responseType, take a look at this.","categories":[],"tags":[{"name":"js","slug":"js","permalink":"http://keyangxiang.com/tags/js/"},{"name":"web","slug":"web","permalink":"http://keyangxiang.com/tags/web/"}]},{"title":"How to make website offline accessible","slug":"Using-service-worker-enables-web-app-offline-usage","date":"2017-08-17T21:23:54.000Z","updated":"2017-12-22T22:08:26.000Z","comments":true,"path":"2017/08/17/Using-service-worker-enables-web-app-offline-usage/","link":"","permalink":"http://keyangxiang.com/2017/08/17/Using-service-worker-enables-web-app-offline-usage/","excerpt":"It is incredibly easy to make a rich web application like psdetch working offline with Service Worker. 5 minutes are all you need!","text":"It is incredibly easy to make a rich web application like psdetch working offline with Service Worker. 5 minutes are all you need! Browser support – by time being Chrome Firefox Edge – In development Safari – In development More browser support details can be found here RequirementTo make your online only web app (like https://studio.psdetch.com) working offline, your web app needs to use https for security request. 5 mins developmentVery simple. The steps below works on any web apps: Follow this guide to install sw-toolbox Add service-worker.js at the root folder of your web app. Here, the location (root folder) is important. Add following script to index.html 12&lt;script src=\"/path/to/sw-toolbox/companion.js\" data-service-worker=\"service-worker.js\"&gt;&lt;/script&gt; Add content to service-worker.js. You can follow the tutorial here. But most situation you can just use following scripts: 12345678910importScripts(\"/path/to/sw-toolbox/sw-toolbox.js\");/* this will cache all files of current web app with * \"fastest\" strategy. */toolbox.router.get(\"/(.*)\",toolbox.fastest);/** Add external files here.e.g.* toolbox.router.get(\"https://code.jquery.com/jquery-3.2.1.min.js\",toolbox.fastest);*/ You can check what I have used for psdetch. And that’s it. Your whole web app can now work offline. With fastest strategy, response is always returned from Cache and updated immediately if possible. This dramatically increased user experience.","categories":[],"tags":[{"name":"js","slug":"js","permalink":"http://keyangxiang.com/tags/js/"},{"name":"web","slug":"web","permalink":"http://keyangxiang.com/tags/web/"}]},{"title":"one line generate server x509 key/cert pair","slug":"one-line-generate-server-x509-key-cert-pair","date":"2017-07-13T12:20:08.000Z","updated":"2017-07-13T12:20:40.000Z","comments":true,"path":"2017/07/13/one-line-generate-server-x509-key-cert-pair/","link":"","permalink":"http://keyangxiang.com/2017/07/13/one-line-generate-server-x509-key-cert-pair/","excerpt":"","text":"1openssl req -nodes -new -x509 -keyout key.pem -out cert.pem -days 365","categories":[],"tags":[]},{"title":"How to setup raspberry pi zero w with MacOS X","slug":"setup-raspberry-pi-zero-w-with-MacOS-X","date":"2017-06-21T22:38:44.000Z","updated":"2017-10-24T23:02:59.000Z","comments":true,"path":"2017/06/21/setup-raspberry-pi-zero-w-with-MacOS-X/","link":"","permalink":"http://keyangxiang.com/2017/06/21/setup-raspberry-pi-zero-w-with-MacOS-X/","excerpt":"Step 1 Prepare toolsTo setup a brand new raspberrypi zero w you need prepare following tools: A raspberrypi zero w mini HDMI to HDMI convert Micro SD card USB OTG Mouse &amp; Keyboard An external SD card reader All coneectors can come from seller when you purchase Raspberrypi zero w.","text":"Step 1 Prepare toolsTo setup a brand new raspberrypi zero w you need prepare following tools: A raspberrypi zero w mini HDMI to HDMI convert Micro SD card USB OTG Mouse &amp; Keyboard An external SD card reader All coneectors can come from seller when you purchase Raspberrypi zero w. Step 2 Download Raspbian ImageYou can download official Raspbian OS from here. If you want use other operation systems, it is same setup setups. Step 3 Write Image to Micro SD cardBe aware, writing image to micro sd card will wipe all data on it Connect micro sd card to your mac through micro sd card reader. Once you can see your sd card in finder, you need find out the disk in system. Open a terminal and run diskutil list: Find your sd card disk by its name. On my machine, the /dev/disk2 in red rectangle is the disk in system and copy disk2 only (not /dev/disk2) into clipboard. Unmount the sd card from finder but do not unplug it. Now, we need flash the image downloaded to sd card. You may need unzip it if the downloaded file is zipped by double click the file in finder. Below is the command to use: 1sudo dd bs=4M if=&lt;path to downloaded .img file&gt; of=/dev/r&lt;disk&gt; Replace the path and &lt;disk&gt; to your own one. Step 4 Plugin and setupNow insert the flashed micro sd card to Raspberrypi Zero W and connect everything and you are ready to go. [Picture] General Problems Resource busy: You need unmount the partitions mounted before you could use dd to write the disk. See above. Permission denied: Make sure write protection on your sd card is open. Also use external SD card reader instead of Mac built-in one which could cause this issue. Operation not permitted: Make sure your device exists in system (check /dev/diskN)","categories":[],"tags":[{"name":"raspberrypi","slug":"raspberrypi","permalink":"http://keyangxiang.com/tags/raspberrypi/"}]},{"title":"how to change MacOSX screenshot location","slug":"how-to-change-MacOSX-screenshot-location","date":"2016-12-21T20:12:34.000Z","updated":"2017-12-22T22:04:01.000Z","comments":true,"path":"2016/12/21/how-to-change-MacOSX-screenshot-location/","link":"","permalink":"http://keyangxiang.com/2016/12/21/how-to-change-MacOSX-screenshot-location/","excerpt":"Taking screenshots with MacOSX is very useful when writting blogs or documents. The system has powerful built-in screenshot function. However, the default location to store the screenshot files is Desktop. This blog will go through how to change the location of screenshots to another folder.","text":"Taking screenshots with MacOSX is very useful when writting blogs or documents. The system has powerful built-in screenshot function. However, the default location to store the screenshot files is Desktop. This blog will go through how to change the location of screenshots to another folder. Step 1 Create a folderCreate a new folder anywhere using finder or terminal. Here I created blog_statics folder in my Google Drive folder. Step 2 Change default location of screenshotsClick the created folder in last step and press Command+C to copy the full path to clipboard. Press Command + Space and type terminal to open terminal In terminal, type following command: 1defaults write com.apple.screencapture location &lt;Folder Location&gt; Note the is the location of your create folder. You could Command+V to paste it from clipboard It should give following result: Now all new screenshots should be stored in that place.","categories":[],"tags":[{"name":"macosx trick","slug":"macosx-trick","permalink":"http://keyangxiang.com/tags/macosx-trick/"}]},{"title":"webworker notes","slug":"webworker-notes","date":"2016-11-13T21:43:04.000Z","updated":"2016-11-22T17:44:46.000Z","comments":true,"path":"2016/11/13/webworker-notes/","link":"","permalink":"http://keyangxiang.com/2016/11/13/webworker-notes/","excerpt":"","text":"WebWorker has now been supported by majority of browsers (link). I have started to use WebWorkers seriously in my projects (web pages / web apps / cordova mobile apps). Below reference pages were used while doing my study: Using webworkers webworker and phonegap","categories":[],"tags":[{"name":"web, javascript","slug":"web-javascript","permalink":"http://keyangxiang.com/tags/web-javascript/"}]},{"title":"openssl quick note","slug":"openssl-quick-note","date":"2016-04-24T11:39:16.000Z","updated":"2017-12-23T00:22:34.000Z","comments":true,"path":"2016/04/24/openssl-quick-note/","link":"","permalink":"http://keyangxiang.com/2016/04/24/openssl-quick-note/","excerpt":"","text":"I found this tutorial is relatively simple to follow to create a simple PKI infrastructure","categories":[],"tags":[{"name":"openssl","slug":"openssl","permalink":"http://keyangxiang.com/tags/openssl/"}]},{"title":"run docker in docker","slug":"run-docker-in-docker","date":"2016-04-07T16:32:14.000Z","updated":"2017-12-23T00:22:41.000Z","comments":true,"path":"2016/04/07/run-docker-in-docker/","link":"","permalink":"http://keyangxiang.com/2016/04/07/run-docker-in-docker/","excerpt":"","text":"Run docker in docker 1docker run --privileged -i -t -d --restart=unless-stopped -p 2376:2376 -p 10000-11000:10000-11000 -p 10000-11000:10000-11000/udp -v /mnt/opt:/opt:rw -v /etc/docker:/etc/docker:ro -v /mnt/var/lib/docker:/var/lib/docker --name=docker docker:dind -H tcp://0.0.0.0:2376 --storage-driver=aufs --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://keyangxiang.com/tags/docker/"}]},{"title":"How to send UDP packet on Linux / Unix?","slug":"use-nc-send-udp-packet","date":"2016-03-31T16:09:54.000Z","updated":"2017-12-23T00:22:48.000Z","comments":true,"path":"2016/03/31/use-nc-send-udp-packet/","link":"","permalink":"http://keyangxiang.com/2016/03/31/use-nc-send-udp-packet/","excerpt":"","text":"Netcat (nc) is very powerful tool. Install apt-get install netcatSend UDP packet with netcat: 1echo \"content goes to server\" | nc -u &lt;ip&gt; &lt;port&gt;","categories":[],"tags":[{"name":"cli","slug":"cli","permalink":"http://keyangxiang.com/tags/cli/"},{"name":"linux","slug":"linux","permalink":"http://keyangxiang.com/tags/linux/"}]},{"title":"Customised select styles","slug":"Customised-select-styles","date":"2016-03-30T23:25:15.000Z","updated":"2017-12-23T00:22:00.000Z","comments":true,"path":"2016/03/31/Customised-select-styles/","link":"","permalink":"http://keyangxiang.com/2016/03/31/Customised-select-styles/","excerpt":"","text":"e.g. 12345678910111213.select-type-1&#123; -webkit-appearance: none; -moz-appearance: none; appearance: none; padding:1em; border:1px solid #ee7122; color:white; text-align: center; border-radius: 0px; -webkit-border-radius: 0px; background: rgba(255, 255, 255, 0.12) url(\"../img/arrowdown.png\") no-repeat 90% 50%; background-size:10%;&#125; self-explained.","categories":[],"tags":[{"name":"html","slug":"html","permalink":"http://keyangxiang.com/tags/html/"},{"name":"css","slug":"css","permalink":"http://keyangxiang.com/tags/css/"}]},{"title":"Docker multi-hosting network quick note","slug":"Docker-multi-hosting-network-quick-note","date":"2016-03-30T17:24:17.000Z","updated":"2017-12-23T00:22:04.000Z","comments":true,"path":"2016/03/30/Docker-multi-hosting-network-quick-note/","link":"","permalink":"http://keyangxiang.com/2016/03/30/Docker-multi-hosting-network-quick-note/","excerpt":"To create an overlay network on multiple hosts over swarm, following are required: a key-value store service: this is used for broadcasting hosts / swarm agents. It can be same kv store swarm used for discovery Run docker daemon with following parameters: cluster-store: where the store is cluster-advertise: what network interface to be advertised","text":"To create an overlay network on multiple hosts over swarm, following are required: a key-value store service: this is used for broadcasting hosts / swarm agents. It can be same kv store swarm used for discovery Run docker daemon with following parameters: cluster-store: where the store is cluster-advertise: what network interface to be advertised Setup consul KV store123456docker run -d \\ -p \"8500:8500\" \\ -h \"consul\" \\ --restart=unless-stopped \\ --name=\"kv_store\"\\ progrium/consul -server -bootstrap Daemon Options12--engine-opt=\"cluster-store=consul://$(docker-machine ip mh-keystore):8500\"--engine-opt=\"cluster-advertise=eth1:2376\" All swarm-agents should have these options otherwise it will be likely get this error: 1Error response from daemon: 500 Internal Server Error: failed to parse pool request for address space \"GlobalDefault\" pool \"\" subpool \"\": cannot find address space GlobalDefault (most likely the backing datastore is not configured) Create overlay networkIf using docker-compose, there is nothing need to do. As docker-compose will automatically create defaul network if: Single host: it will create a bridge Multiple host: it will create a overlay Once docker-compose file finished, just run docker-compose up -d which will create network correspondingly. otherwise simply use following command at your swarm: 1docker network create --driver overlay --subnet=10.0.9.0/24 my-net Docker-compose build on SwarmThere is limitation for docker-compose build as it cannot find the target node to build the image.The only way currently is to build on the node and tag it rather than on swarm. 1docker build -t &lt;tag name&gt; path/to/dockerfile","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://keyangxiang.com/tags/docker/"}]},{"title":"get client ip address in express.js","slug":"get-client-ip-address-in-express-js","date":"2016-03-30T12:47:49.000Z","updated":"2017-12-23T00:22:16.000Z","comments":true,"path":"2016/03/30/get-client-ip-address-in-express-js/","link":"","permalink":"http://keyangxiang.com/2016/03/30/get-client-ip-address-in-express-js/","excerpt":"","text":"According to this, do following to determine the client ipaddress: 1234var ip = (req.headers['x-forwarded-for'] || req.connection.remoteAddress || req.socket.remoteAddress || req.connection.socket.remoteAddress).split(\",\")[0];","categories":[],"tags":[{"name":"node.js","slug":"node-js","permalink":"http://keyangxiang.com/tags/node-js/"},{"name":"express.js","slug":"express-js","permalink":"http://keyangxiang.com/tags/express-js/"}]},{"title":"Quick Note for Unit Tests in Angularjs","slug":"Quick-Note-for-Unit-Tests-in-Angularjs","date":"2016-03-28T14:05:54.000Z","updated":"2017-12-23T00:22:37.000Z","comments":true,"path":"2016/03/28/Quick-Note-for-Unit-Tests-in-Angularjs/","link":"","permalink":"http://keyangxiang.com/2016/03/28/Quick-Note-for-Unit-Tests-in-Angularjs/","excerpt":"Testing with web app is always fun. Angularjs makes it even better.This quick note bootstrap any angular.js projects embracing with unit tests. ToolsUnit testing in Angularjs is using (by default) Jasmine and Karma. Also, angular-mocks needs to be installed. It is needed for injection and some other mock objects. 1bower install --save angular-mocks","text":"Testing with web app is always fun. Angularjs makes it even better.This quick note bootstrap any angular.js projects embracing with unit tests. ToolsUnit testing in Angularjs is using (by default) Jasmine and Karma. Also, angular-mocks needs to be installed. It is needed for injection and some other mock objects. 1bower install --save angular-mocks Npm dependenciesFollowing npm packages are needed and add them as devDependencies: 1234567\"jasmine-core\": \"^2.3.4\",\"karma\": \"~0.12\",\"karma-chrome-launcher\": \"^0.1.12\",\"karma-firefox-launcher\": \"^0.1.6\",\"karma-jasmine\": \"^0.3.5\",\"karma-junit-reporter\": \"^0.2.2\",\"protractor\": \"^2.1.0\" karma.conf.jsConfiguration for karma: 1234567891011121314151617181920212223242526272829303132333435module.exports = function(config)&#123; config.set(&#123; basePath : './', files : [ 'www/bower_components/angular/angular.js', 'www/bower_components/angular-ui-router/release/angular-ui-router.js', 'www/bower_components/angular-mocks/angular-mocks.js', 'www/bower_components/jquery/dist/jquery.js', //all other lib dependencies 'www/app.gen.js', // app js file &lt;- generated by browserfi 'www/app/**/test_*.js' // all tests file ], autoWatch : true, frameworks: ['jasmine'], browsers : ['Chrome'], plugins : [ 'karma-chrome-launcher', 'karma-firefox-launcher', 'karma-jasmine', 'karma-junit-reporter' ], junitReporter : &#123; outputFile: 'test_out/unit.xml', suite: 'unit' &#125; &#125;);&#125;; Put this file at root of project. Run test install karma-cli: npm i -g karma-cli run karma start karma.conf.js This will watch all files and re-run tests if any file changes. Strongly recommended having this opened when developing. Unit tests for angular.jsOnce above setup are done, it is ready to write unit tests. Simple exampleAdd test_user.js to www/app/user/ folder or similar. Just keep test_ file name prefix. 12345678910111213141516describe(\"user module\",function()&#123; beforeEach(module('user')); describe(\"auth factory\",function()&#123; it (\"should manage user session\",inject(function(auth)&#123; auth.initUserWithToken(\"abc\"); expect(auth.getToken().token).toEqual(\"abc\"); auth.setPin(\"1234\"); expect(auth.getToken().pin).toEqual(\"1234\"); expect(auth.validatePin(\"1234\")).toBe(true); expect(auth.validatePin(\"2234\")).toBe(false); auth.logout(); expect(auth.validatePin(\"1234\")).toBe(false); expect(auth.getToken()).toBe(null); &#125;)); &#125;)&#125;); Above, it first injects user module and then runs simple tests. Override providers (factory / service)If component depends on other providers, it’s able to use jasmine.createSpy to create dummy function. 1234567891011121314describe(\"account module\",function()&#123; beforeEach(module('account',function($provide)&#123; $provide.value('server', &#123; call: jasmine.createSpy('call'), setHeader:jasmine.createSpy('setHeader') &#125;); &#125;)); describe(\"account factory\",function()&#123; it (\"should manage accounts\",inject(function(account,server)&#123; account.save(); expect(server.call).toHaveBeenCalled(); &#125;)); &#125;)&#125;); Use $httpBackend for $http callsExample: 1234567891011121314151617181920212223242526describe(\"downStreamStore\",function()&#123; var ds,s,ht; beforeEach(module(\"dataSync\")) beforeEach(inject(function(downStreamStore,server,$httpBackend)&#123; ds=downStreamStore; s=server; ht=$httpBackend; &#125;)) afterEach(function() &#123; ht.verifyNoOutstandingExpectation(); ht.verifyNoOutstandingRequest(); &#125;); it (\"should retrieve data\",function()&#123; ht.when(\"GET\",\"/test\").respond(&#123;\"hello\":\"test\"&#125;) ht.expectGET(\"/test\"); ds.syncData(\"test\",\"/test\") .then(function()&#123; expect(ds.get(\"test\").hello).toBe(\"test\"); &#125;) .catch(function(e)&#123; expect(e).toBeUndefined(); &#125;) ht.flush(); &#125;);&#125;) the test above is synchrounous but with promises. Therefore no need use Jasmine async with done; Quick Reference: Jamine Karma Config Angular Unit Testing Angular Seed (Example of Unit Testing) Angular $httpBackend","categories":[],"tags":[{"name":"angularjs","slug":"angularjs","permalink":"http://keyangxiang.com/tags/angularjs/"},{"name":"test","slug":"test","permalink":"http://keyangxiang.com/tags/test/"}]},{"title":"Using setter in Mongoose","slug":"mongoosejs-setters-schema","date":"2016-03-20T18:16:31.000Z","updated":"2017-12-23T00:22:30.000Z","comments":true,"path":"2016/03/20/mongoosejs-setters-schema/","link":"","permalink":"http://keyangxiang.com/2016/03/20/mongoosejs-setters-schema/","excerpt":"According to mongoose.js doc, it is able to set setters to a field on schema.However, the doc is not quite detailed and obselete.Some example: 1234567891011var schema=new Schema(&#123; password:&#123; type:String, required:true, set:hash &#125;&#125;)function hash(plainPwd)&#123; return require(\"crypto\").createHash(\"sha1\").update(plainPwd).update(secret).digest(\"hex\");&#125;","text":"According to mongoose.js doc, it is able to set setters to a field on schema.However, the doc is not quite detailed and obselete.Some example: 1234567891011var schema=new Schema(&#123; password:&#123; type:String, required:true, set:hash &#125;&#125;)function hash(plainPwd)&#123; return require(\"crypto\").createHash(\"sha1\").update(plainPwd).update(secret).digest(\"hex\");&#125; The hash will be called mainly on following scenarios: When a new doc being created. 1model.create(&#123;password:\"12345\"&#125;) //password will be hashed When set a value to a doc. 1doc.password=\"22222\" // 22222 will be hashed However, this will not work for update query: 123model.update(&#123;_id:&lt;id&gt;&#125;,&#123;$set:&#123;password:\"12345\"&#125;&#125;) // password will not be hashedmodel.findOneAndUpdatemodel.findAndUpdate For password, it is able to write beforeUpdateHook 12345678schema.methods.beforeUpdateHook=function(data)&#123; if (!data || this.password === data.password)&#123; return ; &#125; if (data.password)&#123; data.password=hash(data.password); &#125;&#125;","categories":[],"tags":[{"name":"node.js","slug":"node-js","permalink":"http://keyangxiang.com/tags/node-js/"},{"name":"mongoose.js","slug":"mongoose-js","permalink":"http://keyangxiang.com/tags/mongoose-js/"}]},{"title":"Mongodb two phase lock example (with mongoose)","slug":"Mongodb-two-phase-lock-example","date":"2016-03-17T22:34:09.000Z","updated":"2017-12-23T00:22:24.000Z","comments":true,"path":"2016/03/17/Mongodb-two-phase-lock-example/","link":"","permalink":"http://keyangxiang.com/2016/03/17/Mongodb-two-phase-lock-example/","excerpt":"Mongodb needs extra collection for two phase lock. 123456789var transactionSchema=new Schema(&#123; lastModified:Date, status:&#123; type:String, default:\"new\", index:true &#125;, data:&#123;&#125;&#125;) The transaction life cycle is new-&gt;pending-&gt;applied-&gt;done","text":"Mongodb needs extra collection for two phase lock. 123456789var transactionSchema=new Schema(&#123; lastModified:Date, status:&#123; type:String, default:\"new\", index:true &#125;, data:&#123;&#125;&#125;) The transaction life cycle is new-&gt;pending-&gt;applied-&gt;done NewThe transaction is just created and waiting to be started.Once the transaction is created, the data field would contain all information. e.g. source, destination, cash amount. PendingThe transaction has started but some collection(s) have not finished its operation. When process pending transaction, there are always a series of operations on all related collections and documents. For example, apply a promotion code to an account needs change both promotion collection and user account collection. The changes can happen in parallel or sequence which do not matter. The only important thing is the operation will only affect documents that has not this pending transaction and the operation on the document is done with pushing the pending transaction to the doc. This will need following design: the collection should have a pendingTransaction field which record all current pending transactions on a document. Developer should use update method to update target fields and the pendingTransaction at the same time. Example: 1234567891011121314151617181920var UserSchema=new Schema(&#123; money:Number, pendingTransaction:[ObjectId]&#125;);//Process transactionvar transaction;UserModel.findAndUpdate(&#123; //the query find specified user and gurantee it has not been applied before $ne:&#123; pendingTransaction:transaction._id &#125;, _id:transaction.data.targetUser&#125;,&#123; //update to increase the money and push the transaction to pendingTransaction to mark current user has been applied with the transaction so next application will skip this user account. $push:&#123; pendingTransaction:transaction._id &#125;, $inc:&#123; money:transaction.data.amount &#125;&#125;) After all operations finished, transaction will be marked as applied. If any problems happens during the transaction (e.g. system crashes), the next run through the transaction will ‘skip’ the documents that already being applied and continue applying other operations until the transaction is marked as applied. AppliedThe transaction has made modifications to all related documents. This stage is to clear the pendingTransaction field of those documents ($pull the transaction id from the field.) DoneThe transaction has completed Roll BackThe lastModified field in transaction can be used to judge if a transaction needs to roll-back. (e.g. the lastModified was 5 mins ago but still not successful) Only pending transactions need to be rolled-back as it means there are unfinished changes and some changes have been applied. The roll-back operation is a reverse operation of application operation. e.g. for user document with transaction id in pendingTransaction, pull transaction id from pendingTransaction and decrease the money amount.","categories":[],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"http://keyangxiang.com/tags/mongodb/"}]},{"title":"wordpress reverse proxy headers","slug":"wordpress-reverse-proxy-headers","date":"2016-03-17T21:32:31.000Z","updated":"2017-12-23T00:22:52.000Z","comments":true,"path":"2016/03/17/wordpress-reverse-proxy-headers/","link":"","permalink":"http://keyangxiang.com/2016/03/17/wordpress-reverse-proxy-headers/","excerpt":"","text":"When put wordpress blog behind a reverse proxy (e.g. nginx), some headers have to be setup: 123456proxy_set_header Host $host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_set_header X-Forwarded-Proto $scheme;proxy_set_header HTTP_X_FORWARDED_PROTO $scheme;","categories":[],"tags":[{"name":"wordpress","slug":"wordpress","permalink":"http://keyangxiang.com/tags/wordpress/"},{"name":"nginx","slug":"nginx","permalink":"http://keyangxiang.com/tags/nginx/"}]},{"title":"minimist: a neat cli argv parser","slug":"minimist-a-neat-cli-argv-parser","date":"2016-03-16T17:41:36.000Z","updated":"2017-12-23T00:22:20.000Z","comments":true,"path":"2016/03/16/minimist-a-neat-cli-argv-parser/","link":"","permalink":"http://keyangxiang.com/2016/03/16/minimist-a-neat-cli-argv-parser/","excerpt":"","text":"minimist is a lightweight cli argument (command line arguments) parser: 1234567891011require('minimist')(\"-x 3 -y 4 -n5 -abc --beep=boop foo bar baz\");//output:&#123; _: [ 'foo', 'bar', 'baz' ], x: 3, y: 4, n: 5, a: true, b: true, c: true, beep: 'boop' &#125;","categories":[],"tags":[{"name":"node.js","slug":"node-js","permalink":"http://keyangxiang.com/tags/node-js/"},{"name":"npm","slug":"npm","permalink":"http://keyangxiang.com/tags/npm/"}]},{"title":"css: font-smoothing","slug":"css-font-smoothing","date":"2016-03-16T17:30:36.000Z","updated":"2017-12-23T00:21:55.000Z","comments":true,"path":"2016/03/16/css-font-smoothing/","link":"","permalink":"http://keyangxiang.com/2016/03/16/css-font-smoothing/","excerpt":"","text":"12-webkit-font-smoothing: antialiased;-moz-osx-font-smoothing: grayscale Makes text clearer","categories":[],"tags":[{"name":"css","slug":"css","permalink":"http://keyangxiang.com/tags/css/"}]},{"title":"Docker Quick Notes","slug":"docker-quick-notes","date":"2016-02-10T00:00:00.000Z","updated":"2017-12-23T00:22:10.000Z","comments":true,"path":"2016/02/10/docker-quick-notes/","link":"","permalink":"http://keyangxiang.com/2016/02/10/docker-quick-notes/","excerpt":"What is Docker and why?See here In short: Docker is a container tech based on LXC Much less resource than VM by sharing cores But provide full run-time isolation It makes system deployment much faster and easier system operation Still don’t know why? Check out use cases here","text":"What is Docker and why?See here In short: Docker is a container tech based on LXC Much less resource than VM by sharing cores But provide full run-time isolation It makes system deployment much faster and easier system operation Still don’t know why? Check out use cases here Docker EngineGeneralDocker engine is a command line which interacts with docker daemon to perform RESTful web requests like pulling images, spawn containers etc. Once docker being installed successfully, it is able to use docker in command line to run docker engine. Cannot connect to the Docker daemon. Is the docker daemon running on this host?This error is given if docker cannot connect to $DOCKER_HOST. There are 3 env vars needed to run docker command correctly: DOCKER_HOST: The docker daemon host. It could be something like “tcp://xxx.xxx.xxx.xxx:2376” depends on daemon configuration. DOCKER_TLS_VERIFY: Whether to verify the connection is TLS or not. It could be “1” – TLS only or “0” – TLS disabled. For production “1” is a must be. DOCKER_CERT_PATH: If TLS is enabled, where to find related certs. It points to a folder containing current client private key, certificate and a trusted CA certificate. (ca / cert / key).pem. For more information about TLS, please see here. To switch between Docker daemon instances, change the 3 env vars above to correct ones. With help of Docker Machine, we do not need to do this manually. TipsRun a docker image12docker run -itd &lt;image name&gt;#e.g. docker run -itd nginx This command will pull the image from docker hub if image not existed and then run the default command of the image. -i: Keep STDIN open -t: Allocate a pseudo-TTY. This is essential for logs which directly write to stdout/stderr -d: Detached / run the image in background Run a one-time command in a docker image12docker run -it --rm &lt;image name&gt; &lt;path to shell or bash&gt;#e.g. docker run -it --rm nginx bash This will promt a bash shell allowing typing commands. Typically using this to debug an image see if everything in Dockerfile is correct. –rm: Remove the container after container exited. Without it, the container will remain in container list docker ps -a. Run a command in a running docker container12docker exec -it &lt;container name or hash&gt; &lt;path to command&gt;#e.g. docker exec -it my_nginx_1 bash This will make the running containner to run the command provided. This is very useful to debug a running container. Docker ComposeDocker compose is a single configuration file containing multiple docker containers (services). It allows batching running / stopping. The power of docker compose is it gives very clear architecture of system: The dependencies of each component (services) How services are allocated to different servers (nodes) How network is configured What ports have been exposed to public What environemnt has been configured to each service. Wordpress Example (docker-compose.yaml):12345678910111213141516171819202122232425262728version: '2'services: nginx: image: nginx ports: - 80:80 - 443:443 links: -blog volumes: - /opt/www:/opt/www:ro - /opt/nginx:/etc/nginx/conf.d:ro blog: image: wordpress links: - blog_db environment: - WORDPRESS_DB_HOST=blog_db - WORDPRESS_DB_PASSWORD=xxxxxx volumes: - /opt/www/blog:/var/www/html blog_db: image: mariadb environment: - MYSQL_ROOT_PASSWORD=xxxxxx volumes: - /opt/data/blog:/var/lib/mysql:rw The example above show the cluster has 3 parts which compose a wordpress blog system. For more about docker compose. See here. Network &amp;&amp; LinksDocker compose will automatically create a overlay network which has all services registered under same network. That means all service can access each other through its name. In the example, it is able to ping blog from nginx container. Docker MachineDocker machine is a VM level tool. It helps provision a bare VM (or non-bare VM) to be docker ready. It is highly recommended to provision Docker daemon using this way on your own VM. It has a bunch of built-in drivers like digital ocean, aws etc. However, as long as you got SSH access and root account, it should not be a big problem. Example: provision on Digital Ocean1docker-machine create -d \"digitalocean\" --digitalocean-access-token \"&lt;digitalocean api token&gt;\" -digitalocean-region \"lon1\" my-dm -d: driver to use. See here for list of drivers. Once it is finished. The new machine can be found with docker-machine ps. Point to a machine1eval $(docker-machine env &lt;my-dm&gt;) This command will set essential env vars for docker engine. Backup your machines !!!The docker-machine will use /.docker/machine to store all your certs / configurations.Backup it and protect it. Docker SwarmDocker swarm is an awesome concept that treats multiple docker daemons as one. This means you can horizontally scale your cluster without worrying about many changes in your DevOps progress. Docker swarm is another RESTful service layer which has exact same endpoints as Docker Daemon does. It has builtin strategies (like spread) to pick the actual node (server) to use. Docker engine 100% works with docker swarm service. Docker swarm is transparent to any docker engine. Is it completely transparent?No. There are still some configuration needed to make things work like network, volume mapping etc. With help of Docker compose, the swarm can be configured easily. See here for limitations with Docker Swarm. DiscoveryDocker swarm depends on a discovery service which itself could be a docker service.The swarm network and discovery service is de-centralised and clustered which means better availability.Using swarm join will regiser itself to discovery service and swarm manager can then collect information from the discovery service.It is able to use: token proto: for non production etcd consuland some other key-value stores. Tokentoken is hosted on docker.com. Typeically not used for prod. Generate a token: 1docker run --rm swarm create Then it is able to use token://&lt;tokenID&gt; as discovery service Swarm Manager TLSAs docker swarm manager needs to actively manage swarm agents, it needs have its own TLS certificates signed by same CA. Otherwise, swarm manager will not be able to talk to swarm agents.For example: 1docker run -d -p 3376:3376 -t -v /var/lib/boot2docker:/certs:ro swarm manage -H 0.0.0.0:3376 --tlsverify --tlscacert=/certs/ca.pem --tlscert=/certs/server.pem --tlskey=/certs/server-key.pem token://123456789 Run container on specific Swarm agent12environment: - \"constraint:node==node-1\" the node-1 can be name of the docker machine. #Docker Engine Restart policy1docker run --restart =&lt;restart strategy &gt; &lt;image name&gt; Restart strategies: no on-failure[:max-retries] always unless-stopped give a name1docker run --name=&lt;name&gt; &lt;image name&gt;","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://keyangxiang.com/tags/docker/"}],"author":"Keyang Xiang"},{"title":"How to make textarea resizable and change its default outline style","slug":"textarea-quick-hack","date":"2016-01-12T10:35:25.000Z","updated":"2017-12-23T00:22:45.000Z","comments":true,"path":"2016/01/12/textarea-quick-hack/","link":"","permalink":"http://keyangxiang.com/2016/01/12/textarea-quick-hack/","excerpt":"","text":"ResizeSwitch on / off resize of a textarea on horizontal / vertical / both. 1&lt;textarea style=\"resize:horizontal\"&gt;&lt;/textarea&gt; The resize property can be either: vertical: only resize vertically horizontal: only resize horizontally none: disable resize (also remove the resize area on right bottom.) OutlineRemove or change style of outline when textarea is focused on safari / chrome etc. 1&lt;textarea class=\"customize\"&gt;&lt;/textarea&gt; 123.customize:focus&#123; outline-color:red;&#125; .customize:focus{ outline-color:red; }","categories":[],"tags":[{"name":"html","slug":"html","permalink":"http://keyangxiang.com/tags/html/"},{"name":"css","slug":"css","permalink":"http://keyangxiang.com/tags/css/"}]},{"title":"Move to Hexo","slug":"move-to-hexo-blog","date":"2016-01-10T13:47:15.000Z","updated":"2016-01-10T13:47:15.000Z","comments":true,"path":"2016/01/10/move-to-hexo-blog/","link":"","permalink":"http://keyangxiang.com/2016/01/10/move-to-hexo-blog/","excerpt":"Today, I moved my blog from Wordpress to Hexo. I use github.io to host the blog. The reason I choose Hexo not Jekyll mainly is I am more familiar with Node.js than Ruby so I can write plugins easily. Hexo is a very powerful static content generator which converts MarkDown posts to Html.","text":"Today, I moved my blog from Wordpress to Hexo. I use github.io to host the blog. The reason I choose Hexo not Jekyll mainly is I am more familiar with Node.js than Ruby so I can write plugins easily. Hexo is a very powerful static content generator which converts MarkDown posts to Html. To install Hexo, simply: 123npm install -g hexohex init #create a new blog in current foldernpm install . #install dependencies To serve content locally: 1hexo serve To generate static content: 1hexo g To deploy to github: open _config.yml add deploy section: 1234deploy: type: git repo: &lt;your github.io repo&gt; branch: master then run: 1hexo deploy -g There are still a lot of powerful function in Hexo. Check here for more details.","categories":[],"tags":[]},{"title":"Online CSV to JSON Convert","slug":"csv2json","date":"2012-03-26T23:00:00.000Z","updated":"2016-01-11T16:27:01.000Z","comments":true,"path":"2012/03/27/csv2json/","link":"","permalink":"http://keyangxiang.com/2012/03/27/csv2json/","excerpt":"","text":"Demo: Click here Document &amp; API: See Github site for more information.","categories":[],"tags":[{"name":"misc","slug":"misc","permalink":"http://keyangxiang.com/tags/misc/"}]}]}